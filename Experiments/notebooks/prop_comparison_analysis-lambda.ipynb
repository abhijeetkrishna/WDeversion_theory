{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to compute deformation map of the wing disc pouch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Missing module name.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set some parameters for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all of this can be put into a function \n",
    "\n",
    "#first we select the genotype \n",
    "genotype = 'ecadGFPnbG4'\n",
    "#genotype = 'ecadGFPnbG4myoVI'\n",
    "\n",
    "#some lists and dicts that we refer to later\n",
    "\n",
    "#update names of devstages\n",
    "devstage_map = {\n",
    "                \"96hAEL\":\"96hAEL\",\n",
    "                \"120hAEL\":\"120hAEL\",\n",
    "                \"upcrawling\":\"wL3\",\n",
    "                \"whitePupa\":\"0hAPF\",\n",
    "                \"2hAPF\":\"2hAPF\",\n",
    "                \"4hAPF\":\"4hAPF\",\n",
    "                \"6hAPF\":\"6hAPF\",\n",
    "               }\n",
    "\n",
    "#declare colors for each devstage and crosssection and region\n",
    "color_dict = {\n",
    "              '96hAEL':'#f1ef81',\n",
    "              '120hAEL':'#efa636',\n",
    "              'wL3':'#414243',\n",
    "              '0hAPF':'#7d99cd', \n",
    "              '2hAPF':'#64a9dd', \n",
    "              '4hAPF':'#78cfdb',\n",
    "              '6hAPF':'#71c382',\n",
    "              'DV' : 'purple',\n",
    "              'outDV' : 'green',\n",
    "             }\n",
    "\n",
    "columns = ['devstage', 'discName', 'region', 'k_dist', #'roi',\n",
    "           'area','neighbour_number','elongation_tensor_norm_max', \n",
    "           'Qrr_geom_inPlane', 'Qphiphi', 'Qnn', 'Qrphi', 'Qrn', 'Qphin',\n",
    "           'countInBin', 'cumcount',\n",
    "           'k_dist_pathlength', #'k_dist_pathlength_poly' \n",
    "          ]\n",
    "\n",
    "rois = ['outDV', 'DV']\n",
    "devstages = [#\"96hAEL\",\n",
    "             \"wL3\",\"0hAPF\",\"2hAPF\",\"4hAPF\", \"6hAPF\",\n",
    "]\n",
    "\n",
    "############################################\n",
    "# Dictionary of pairs of stages to compare #\n",
    "############################################\n",
    "\n",
    "#for the simulations, we use the cumulative version\n",
    "devstage_combinations = pd.DataFrame({'devstage_init':[\n",
    "                                                       #'wL3','0hAPF','2hAPF',#'4hAPF' #diff between consecutive stages\n",
    "                                                       'wL3','wL3','wL3', #'wL3' #cumulative\n",
    "    \n",
    "                                                      ],\n",
    "                                     'devstage_final':[\n",
    "                                                       #'4hAPF',\n",
    "                                                       '0hAPF','2hAPF','4hAPF',#'6hAPF' \n",
    "                                                      ],}\n",
    "                                    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "DFallDiscsIncreaselimitcounts = pd.read_pickle(\"../raw_data/DFallDiscsIncreaselimitcounts.pkl\")\n",
    "DFallDiscslimitcounts = pd.read_pickle(\"../raw_data/DFallDiscslimitcounts.pkl\")\n",
    "\n",
    "#change names in dataframes\n",
    "df = DFallDiscsIncreaselimitcounts #pd.read_pickle('../data/DFallDiscsIncreaselimitcounts.pkl')\n",
    "#df = pd.read_pickle('../data/DFallDiscslimitcounts.pkl')\n",
    "df = df[df['genotype'] == genotype]\n",
    "df[\"devstage\"] = [devstage_map[x] for x in df[\"devstage\"].values]\n",
    "df = df[columns]\n",
    "\n",
    "df_limit = DFallDiscslimitcounts #pd.read_pickle('../data/DFallDiscslimitcounts.pkl')\n",
    "df_limit = df_limit[df_limit['genotype'] == genotype]\n",
    "df_limit[\"devstage\"] = [devstage_map[x] for x in df_limit[\"devstage\"].values]\n",
    "df_limit = df_limit[columns]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging within each ring\n",
    "For each disc, compute average quantities within each ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discName contains the name of the disc as well as region\n",
    "groupby_cols = ['devstage', 'region', 'discName', 'k_dist'] #here grouping by region is redundant because discName contains region\n",
    "#here we pool cells within a ring and calculate the mean\n",
    "df_pool_k = df.groupby(groupby_cols).agg('mean').reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute Qnorm and exponential of Qnorm - to be used later\n",
    "\n",
    "#function to compute area weighted average\n",
    "wm = lambda x: np.average(x, weights=df.loc[x.index, \"area\"])\n",
    "\n",
    "df_pool_areaWeighted_k = df.groupby(groupby_cols).agg(Qrr_geom_inPlane = pd.NamedAgg(column = 'Qrr_geom_inPlane', aggfunc = wm),\n",
    "                                                      Qrphi = pd.NamedAgg(column = 'Qrphi', aggfunc = wm),\n",
    "                                                      Qphiphi = pd.NamedAgg(column = 'Qphiphi', aggfunc = wm),\n",
    "                                                     ).reset_index() \n",
    "df_pool_k[[\"Qrr_geom_inPlane\", \"Qrphi\", \"Qphiphi\"]] = df_pool_areaWeighted_k[[\"Qrr_geom_inPlane\", \"Qrphi\", \"Qphiphi\"]]\n",
    "\n",
    "df_pool_k['Qnorm'] = np.sqrt(df_pool_k['Qrr_geom_inPlane']**2 + df_pool_k['Qrphi']**2)\n",
    "df_pool_k['exp_signed_Qnorm'] = np.exp(np.sign(df_pool_k['Qrr_geom_inPlane'])*df_pool_k['Qnorm'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging within each developmental stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_cols = ['devstage', 'region', 'k_dist']\n",
    "#here we pool discs within a devstage and calculate the mean and std\n",
    "df_pool_k_num = df_pool_k.drop('discName', axis=1, inplace=False)\n",
    "df_pool_devstage = df_pool_k_num.groupby(groupby_cols).agg(['mean', 'std']).reset_index()\n",
    "colnames = [x[0]+'_'+x[1] if x[0] not in groupby_cols else x[0] for x in df_pool_devstage.columns]\n",
    "df_pool_devstage.columns = colnames #removing multi-indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute Qnorm\n",
    "df_pool_devstage['Qnorm_mean'] =  np.sqrt( df_pool_devstage['Qrr_geom_inPlane_mean']**2 + df_pool_devstage['Qrphi_mean']**2)\n",
    "df_pool_devstage['Qnorm_std'] = (1/df_pool_devstage['Qnorm_mean'])*np.sqrt( (df_pool_devstage['Qrr_geom_inPlane_mean']*df_pool_devstage['Qrr_geom_inPlane_std'])**2 + (df_pool_devstage['Qrphi_mean']*df_pool_devstage['Qrphi_std'])**2 )\n",
    "#compute exp_signed_Qnorm\n",
    "df_pool_devstage['exp_signed_Qnorm_mean'] = np.exp(np.sign(df_pool_devstage['Qrr_geom_inPlane_mean'])*df_pool_devstage['Qnorm_mean'])\n",
    "df_pool_devstage['exp_signed_Qnorm_std'] = df_pool_devstage['exp_signed_Qnorm_mean']*df_pool_devstage['Qnorm_std']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda comparison\n",
    "\n",
    "- For each region and stage combination (a devstage_init and a devstage_final), separate a df_init which comes out of df_pool_k[df_pool_k[“devstage”] == devstage_init]. Stack each of these dataframes to make df_discs_compared. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discs_compared = pd.DataFrame()\n",
    "regions = [\"DV\", \"outDV\"]\n",
    "for region in regions:\n",
    "    for i in range(len(devstage_combinations)):\n",
    "        [devstage_init, devstage_final] = devstage_combinations.iloc[i][[\"devstage_init\", \"devstage_final\"]].values\n",
    "        df_temp = df_pool_k.query(\"region == @region and devstage == @devstage_init\").reset_index()\n",
    "        df_temp[\"devstage_final\"] = devstage_final \n",
    "        df_temp = df_temp.rename(columns={\"devstage\": \"devstage_init\"})\n",
    "        df_discs_compared = pd.concat([df_discs_compared,df_temp], axis=0)\n",
    "\n",
    "cols = [\"region\", \"devstage_init\", \"devstage_final\", \"discName\", \"cumcount\"]\n",
    "spcl_cols = [\"area\", \"exp_signed_Qnorm\", \"k_dist\", \"k_dist_pathlength\"] #to be renamed\n",
    "all_cols = cols + spcl_cols\n",
    "df_discs_compared = df_discs_compared[cols + spcl_cols]\n",
    "for col in spcl_cols: df_discs_compared = df_discs_compared.rename(columns={col:col + \"_init\"})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Group by [disc, devstage_init, devstage_final, region] - let us call each disc in this group as disc_init\n",
    "- For the disc_init, we need to compute props = [area_final, exp_signed_Qnorm_final, k_dist_final]. For each prop, get a dataframe (df_discs_final) where the index is the cumcount of disc_init and each column is the interpolated value of that prop for all disc_final. Compute k_NDiff_specially. Take the average across all columns (disc_final) and use that series to populate the prop_final for that disc_init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_interpolated_values(col, prop):\n",
    "\n",
    "    #this function fetches the interpolated values for a given property\n",
    "    #for a given discName in the final devstage\n",
    "    #the values are interpolated on the cumcount values of the disc of the initial devstage\n",
    "    disc_final = col.name\n",
    "    cumcounts = col.index\n",
    "    df_disc_final = df_pool_k.query(\"discName == @disc_final\")[[\"cumcount\", prop]]\n",
    "    interpolated_values = np.interp(cumcounts, df_disc_final.cumcount.values, df_disc_final[prop].values)\n",
    "\n",
    "    return(interpolated_values)\n",
    "\n",
    "def comparison_helper(df):\n",
    "    \n",
    "    #this function is run for each disc of the initial devstage\n",
    "    #for each of these discs, properties like area and exp_signed_Qnorm in the final devstage are computed\n",
    "    devstage_final = df.iloc[0][\"devstage_final\"] \n",
    "    region = df.iloc[0][\"region\"]\n",
    "    cumcounts = df.cumcount.values\n",
    "    discs_final = np.unique(df_pool_k.query(\"devstage == @devstage_final and region == @region\")[\"discName\"])\n",
    "    df_discs_final = pd.DataFrame(index=cumcounts, columns=discs_final)\n",
    "    df[\"k_dist_pathlength_final\"] = df_discs_final.apply(fetch_interpolated_values, axis = 0, prop = \"k_dist_pathlength\").mean(axis = 1).values \n",
    "    df[\"area_final\"] = df_discs_final.apply(fetch_interpolated_values, axis = 0, prop = \"area\").mean(axis = 1).values\n",
    "    df[\"exp_signed_Qnorm_final\"] = df_discs_final.apply(fetch_interpolated_values, axis = 0, prop = \"exp_signed_Qnorm\").mean(axis = 1).values\n",
    "    df[\"k_dist_final\"] = df_discs_final.apply(fetch_interpolated_values, axis = 0, prop = \"k_dist\").mean(axis = 1).values\n",
    "    df['k_Ndiff_forward'] = df['k_dist_final'].transform(lambda x: x - x.shift(1))\n",
    "    df['k_Ndiff_backward'] = df['k_dist_final'].transform(lambda x: x.shift(-1) - x)\n",
    "    #averaging the forward and backward values\n",
    "    df['k_Ndiff_final'] = df[['k_Ndiff_forward', 'k_Ndiff_backward']].mean(axis=1)\n",
    "\n",
    "    return(df)\n",
    "\n",
    "df_discs_compared = df_discs_compared.groupby([\"discName\", \"region\", \"devstage_init\", \"devstage_final\"]).apply(comparison_helper).reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each lambda can be calculated for each row of df_discs_compared with a single line of code. Compute lambda_anisotropic specially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discs_compared[\"lambda_isotropic\"] = np.sqrt(df_discs_compared[\"area_final\"]/df_discs_compared[\"area_init\"])\n",
    "df_discs_compared[\"lambda_Q\"] = df_discs_compared[\"exp_signed_Qnorm_final\"]/df_discs_compared[\"exp_signed_Qnorm_init\"]\n",
    "df_discs_compared[\"lambda_rearrangement\"] = df_discs_compared[\"k_Ndiff_final\"]/1.0 # df_discs_compared[\"k_Ndiff_init\"] = 1\n",
    "df_discs_compared[\"lambda_anisotropic\"] = df_discs_compared[\"lambda_Q\"]*df_discs_compared[\"lambda_rearrangement\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make a new dataframe: df_discs_compared > group by [devstage_init, devstage_final, region] > aggregate by [average, std] > df_compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_cols = [\"devstage_init\", \"devstage_final\", \"region\", \"k_dist_init\"]\n",
    "df_comparison = df_discs_compared.drop(columns=[\"discName\"])\\\n",
    "                .groupby(groupby_cols).agg(['mean', 'std']).reset_index()\n",
    "#removing multi-indexing\n",
    "colnames = [x[0]+'_'+x[1] if x[0] not in groupby_cols else x[0] for x in df_comparison.columns]\n",
    "df_comparison.columns = colnames \n",
    "#replace the following patterns - [\"_init_mean\" -> \"_mean_init\", \"_final_mean\" -> \"_mean_final\"] and same pattern for std\n",
    "colnames =[x.replace(\"_init_mean\", \"_mean_init\").replace(\"_final_mean\", \"_mean_final\").replace(\"_init_std\", \"_std_init\").replace(\"_final_std\", \"_std_final\")\n",
    "            for x in df_comparison.columns]\n",
    "df_comparison.columns = colnames \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limit N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check from df_limit the highest values of k_dist for each region and devstage\n",
    "k_limits = df_limit.groupby([\"region\", \"devstage\"])[\"k_dist\"].max().reset_index()\n",
    "#rename columns to match df_comparison - note that devstage is renamed to devstage_init because that is the reference devstage\n",
    "k_limits = k_limits.rename(columns={\"k_dist\": \"k_dist_max\", \"devstage\": \"devstage_init\"})\n",
    "#for every row, store the k_dist_max value for its corresponding region and devstage\n",
    "df_comparison[\"k_dist_max\"] = df_comparison.apply(lambda x: k_limits[(k_limits[\"region\"] == x[\"region\"]) & (k_limits[\"devstage_init\"] == x[\"devstage_init\"])][\"k_dist_max\"].values[0], axis=1)\n",
    "#alternative would be merge but it reshuffles row order so not doing that - pd.merge(df_comparison, k_limits, on=[\"region\", \"devstage_init\"])\n",
    "#drop rows for which k_dist is higher than k_dist_max\n",
    "df_comparison = df_comparison[df_comparison[\"k_dist_init\"] <= df_comparison[\"k_dist_max\"]].reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize pathlengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the reference pathlength - pathlength of the initial state\n",
    "#calculate the scaled pathlength for each region and devstage\n",
    "pathlength_limits = df_comparison.groupby([\"region\", \"devstage_init\"])[\"k_dist_pathlength_mean_init\"].max().reset_index()\n",
    "df_comparison[\"ref_pathlength_max\"] = df_comparison.apply(lambda x: pathlength_limits[(pathlength_limits[\"region\"]==x[\"region\"]) & (pathlength_limits[\"devstage_init\"]==x[\"devstage_init\"])][\"k_dist_pathlength_mean_init\"].values[0], axis=1)\n",
    "#normalize pathlength by the maximum pathlength in the respective region and devstage\n",
    "df_comparison[\"ref_pathlength_scaled\"] = df_comparison[\"k_dist_pathlength_mean_init\"]/df_comparison[\"ref_pathlength_max\"]\n",
    "df_comparison[\"ref_pathlength_scaled_std\"] = df_comparison[\"k_dist_pathlength_std_init\"]/df_comparison[\"ref_pathlength_max\"]\n",
    "\n",
    "#scaling the pathlength of the final state\n",
    "pathlength_limits = df_comparison.groupby([\"region\", \"devstage_final\"])[\"k_dist_pathlength_mean_final\"].max().reset_index()\n",
    "df_comparison[\"pathlength_max\"] = df_comparison.apply(lambda x: pathlength_limits[(pathlength_limits[\"region\"]==x[\"region\"]) & (pathlength_limits[\"devstage_final\"]==x[\"devstage_final\"])][\"k_dist_pathlength_mean_final\"].values[0], axis=1)\n",
    "#normalize pathlength by the maximum pathlength in the respective region and devstage\n",
    "df_comparison[\"pathlength_scaled\"] = df_comparison[\"k_dist_pathlength_mean_final\"]/df_comparison[\"pathlength_max\"]\n",
    "df_comparison[\"pathlength_scaled_std\"] = df_comparison[\"k_dist_pathlength_std_final\"]/df_comparison[\"pathlength_max\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit straight lines to lambda values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = [\"lambda_isotropic_mean\", \"lambda_Q_mean\", \"lambda_rearrangement_mean\", \"lambda_anisotropic_mean\"]\n",
    "fit_param = \"ref_pathlength_scaled\"\n",
    "fit_deg = 1\n",
    "\n",
    "def fit_func(x):\n",
    "    ind = x.index\n",
    "    coeffs = np.polyfit(df_comparison.iloc[ind][fit_param], df_comparison.iloc[ind][prop], deg = fit_deg)\n",
    "    return([coeffs])\n",
    "\n",
    "fit_lambdas_df = pd.DataFrame()\n",
    "for prop in props:\n",
    "    df_temp = df_comparison.groupby([\"devstage_init\", \"devstage_final\", \"region\"])[prop].agg(fit_func).reset_index()\n",
    "    df_temp[\"prop\"] = prop \n",
    "    df_temp = df_temp.rename(columns={prop: \"value\"})\n",
    "    fit_lambdas_df = pd.concat([fit_lambdas_df,df_temp], axis=0)\n",
    "\n",
    "fit_lambdas_df[\"value\"] = fit_lambdas_df[\"value\"].apply(lambda x: x[0],) #remove list to keep only numpy array\n",
    "fit_lambdas_df[\"poly_obj\"] = fit_lambdas_df[\"value\"].apply(lambda x: np.poly1d(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each prop, make a temporary column\n",
    "#in that column add the polynomial object by matching devstage_init, devstage_final and region\n",
    "#then add the value of the polynomial object to the fit_prop column\n",
    "\n",
    "for prop in props:\n",
    "\n",
    "    df_comparison[\"temp_obj\"] = df_comparison.apply(lambda row: fit_lambdas_df.query(\"region == @row.region & devstage_init == @row.devstage_init & devstage_final == @row.devstage_final & prop == @prop\").poly_obj.values[0], axis=1)\n",
    "    df_comparison[\"fit_\"+prop] = df_comparison.apply(lambda row: row[\"temp_obj\"](row[\"ref_pathlength_scaled\"]), axis=1)\n",
    "df_comparison = df_comparison.drop(columns=[\"temp_obj\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save lambdas for simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>stage_name</th>\n",
       "      <th>prop</th>\n",
       "      <th>value</th>\n",
       "      <th>stage_init</th>\n",
       "      <th>stage_final</th>\n",
       "      <th>roi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>wL3 to 0hAPF</td>\n",
       "      <td>inDV_lambda_isotropic_coeffs</td>\n",
       "      <td>[-0.08332494663226647, 1.1824277089755426]</td>\n",
       "      <td>wL3</td>\n",
       "      <td>0hAPF</td>\n",
       "      <td>DV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>wL3 to 0hAPF</td>\n",
       "      <td>lambda_isotropic_coeffs</td>\n",
       "      <td>[-0.11187447249016479, 1.195668113652946]</td>\n",
       "      <td>wL3</td>\n",
       "      <td>0hAPF</td>\n",
       "      <td>outDV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>wL3 to 2hAPF</td>\n",
       "      <td>inDV_lambda_isotropic_coeffs</td>\n",
       "      <td>[-0.0975686268912601, 1.1621873503412041]</td>\n",
       "      <td>wL3</td>\n",
       "      <td>2hAPF</td>\n",
       "      <td>DV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wL3 to 2hAPF</td>\n",
       "      <td>lambda_isotropic_coeffs</td>\n",
       "      <td>[-0.3113532586427171, 1.423238945363028]</td>\n",
       "      <td>wL3</td>\n",
       "      <td>2hAPF</td>\n",
       "      <td>outDV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>wL3 to 4hAPF</td>\n",
       "      <td>inDV_lambda_isotropic_coeffs</td>\n",
       "      <td>[-0.04153988523612025, 1.4031718377579208]</td>\n",
       "      <td>wL3</td>\n",
       "      <td>4hAPF</td>\n",
       "      <td>DV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stage    stage_name                          prop  \\\n",
       "0      0  wL3 to 0hAPF  inDV_lambda_isotropic_coeffs   \n",
       "1      0  wL3 to 0hAPF       lambda_isotropic_coeffs   \n",
       "2      1  wL3 to 2hAPF  inDV_lambda_isotropic_coeffs   \n",
       "3      1  wL3 to 2hAPF       lambda_isotropic_coeffs   \n",
       "4      2  wL3 to 4hAPF  inDV_lambda_isotropic_coeffs   \n",
       "\n",
       "                                        value stage_init stage_final    roi  \n",
       "0  [-0.08332494663226647, 1.1824277089755426]        wL3       0hAPF     DV  \n",
       "1   [-0.11187447249016479, 1.195668113652946]        wL3       0hAPF  outDV  \n",
       "2   [-0.0975686268912601, 1.1621873503412041]        wL3       2hAPF     DV  \n",
       "3    [-0.3113532586427171, 1.423238945363028]        wL3       2hAPF  outDV  \n",
       "4  [-0.04153988523612025, 1.4031718377579208]        wL3       4hAPF     DV  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#name of lambda includes the region it belongs to \n",
    "fit_lambdas_df = fit_lambdas_df.rename(columns = {\"region\": \"roi\", \"devstage_init\":\"stage_init\", \"devstage_final\":\"stage_final\"})\n",
    "\n",
    "fit_lambdas_df[\"prop\"] = fit_lambdas_df.apply(lambda row: \"inDV_\"+row[\"prop\"].replace(\"_mean\", \"_coeffs\") if row[\"roi\"]==\"DV\" else row[\"prop\"].replace(\"_mean\", \"_coeffs\") ,axis = 1)\n",
    "#a string name to each transition\n",
    "fit_lambdas_df[\"stage_name\"] = fit_lambdas_df.apply(lambda row: row[\"stage_init\"] + \" to \" + row[\"stage_final\"], axis = 1)\n",
    "\n",
    "#a numeric name to each transition\n",
    "devstage_combinations[\"stage_name\"] = devstage_combinations[\"devstage_init\"] + \" to \" + devstage_combinations[\"devstage_final\"]\n",
    "devstage_combinations[\"stage_num_name\"] = devstage_combinations.index\n",
    "stage_name_dict = devstage_combinations.set_index('stage_name')['stage_num_name'].to_dict()\n",
    "fit_lambdas_df[\"stage\"] = fit_lambdas_df.apply(lambda row: stage_name_dict[row[\"stage_name\"]], axis = 1)\n",
    "\n",
    "#reset index\n",
    "fit_lambdas_df = fit_lambdas_df.reset_index(drop=True)\n",
    "#select only relevant columns\n",
    "fit_lambdas_df = fit_lambdas_df[[\"stage\", \"stage_name\", \"prop\", \"value\", \"stage_init\", \"stage_final\", \"roi\"]]\n",
    "\n",
    "#save this csv\n",
    "os.makedirs(\"../analyzed_output\", exist_ok=True)\n",
    "fit_lambdas_df.to_csv(\"../analyzed_output/fit_lambdas_df_\" + genotype + \".csv\", index = False)\n",
    "#save pickle\n",
    "fit_lambdas_df.to_pickle(\"../analyzed_output/fit_lambdas_df_\" + genotype + \".pkl\")\n",
    "\n",
    "fit_lambdas_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save df_comparison df to csv\n",
    "df_comparison.to_csv('../analyzed_output/stages_comparison_df_' + genotype + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WD_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
